# Import the libraries
import torch
from transformers import BartTokenizer, BartForConditionalGeneration

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
 
# Load the model and the tokenizer
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')
model.to("cuda")
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')

 
# Define the text to be summarized
text = """
	In this tutorial, you have learned how to use PyTorch and HuggingFace to perform text summarization with BART, a state-of-the-art model for both extractive and abstractive summarization. You have learned:

    What is text summarization and what are the main types and challenges of this task.
    What is BART and how does it work for text summarization.
    How to load BART with HuggingFace and use it to generate summaries of text data.
    How to fine-tune BART for text summarization on a custom dataset.
    How to evaluate BART for text summarization using various metrics.
    Examples of summaries generated by BART on different types of text data.

	By following this tutorial, you have gained some practical skills in using PyTorch and HuggingFace for NLP tasks. You have also gained a solid understanding of text summarization with BART and how to apply it to your own projects.

	Text summarization is a powerful and useful technique that can help you quickly grasp the main points and key information of a large amount of text, saving time and effort. With BART, you can generate high-quality summaries of different types of text data, using PyTorch and HuggingFace.

	We hope you enjoyed this tutorial and found it helpful. If you have any questions, feedback, or suggestions, please let us know in the comments below. We would love to hear from you and improve this tutorial for future readers.

	Thank you for reading and happy summarizing!
"""
 
# Encode the text and generate the summary
input_ids = tokenizer(text, return_tensors='pt').input_ids.cuda()
output_ids = model.generate(input_ids, num_beams=4, length_penalty=2.0, max_length=150, min_length=30, no_repeat_ngram_size=3)
summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)
 
# Print the summary
print("Summary:\n", summary)