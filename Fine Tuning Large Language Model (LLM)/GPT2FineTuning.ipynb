{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5b5ff327-a395-4f1d-b94e-7d523026b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchtext transformers sentencepiece pandas tqdm datasets notebook \n",
    "#!pip install tqdm\n",
    "# https://habr.com/ru/articles/859250/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb1894e1-0f5c-4351-91e9-443ccb87b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d3779784-c8f1-4121-ac6d-332bc9efb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "data_sample = load_dataset(\"QuyenAnhDE/Diseases_Symptoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d9760b35-e23f-409a-8623-3520e68889aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Code', 'Name', 'Symptoms', 'Treatments'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bbb68dc4-3f94-439d-be3d-c98351641b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = [{'Name': item['Name'], \n",
    "                 'Symptoms': item['Symptoms'], \n",
    "                 'Treatments': item['Treatments'],\n",
    "                } for item in data_sample['train']]\n",
    "df = pd.DataFrame(updated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7e6d7dfb-a81a-4b28-8be0-e79199ac8f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Treatments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panic disorder</td>\n",
       "      <td>Palpitations, Sweating, Trembling, Shortness o...</td>\n",
       "      <td>Antidepressant medications, Cognitive Behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal cord polyp</td>\n",
       "      <td>Hoarseness, Vocal Changes, Vocal Fatigue</td>\n",
       "      <td>Voice Rest, Speech Therapy, Surgical Removal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turner syndrome</td>\n",
       "      <td>Short stature, Gonadal dysgenesis, Webbed neck...</td>\n",
       "      <td>Growth hormone therapy, Estrogen replacement t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptorchidism</td>\n",
       "      <td>Absence or undescended testicle(s), empty scro...</td>\n",
       "      <td>Observation and monitoring (in cases of mild o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethylene glycol poisoning-1</td>\n",
       "      <td>Nausea, vomiting, abdominal pain, General mala...</td>\n",
       "      <td>Supportive Measures, Gastric Decontamination, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0               Panic disorder   \n",
       "1             Vocal cord polyp   \n",
       "2              Turner syndrome   \n",
       "3               Cryptorchidism   \n",
       "4  Ethylene glycol poisoning-1   \n",
       "\n",
       "                                            Symptoms  \\\n",
       "0  Palpitations, Sweating, Trembling, Shortness o...   \n",
       "1           Hoarseness, Vocal Changes, Vocal Fatigue   \n",
       "2  Short stature, Gonadal dysgenesis, Webbed neck...   \n",
       "3  Absence or undescended testicle(s), empty scro...   \n",
       "4  Nausea, vomiting, abdominal pain, General mala...   \n",
       "\n",
       "                                          Treatments  \n",
       "0  Antidepressant medications, Cognitive Behavior...  \n",
       "1       Voice Rest, Speech Therapy, Surgical Removal  \n",
       "2  Growth hormone therapy, Estrogen replacement t...  \n",
       "3  Observation and monitoring (in cases of mild o...  \n",
       "4  Supportive Measures, Gastric Decontamination, ...  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "34f2a3b6-6657-4986-9c26-b09819754457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8a31cfa9-3688-4abc-85f2-5d9a6239223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e7d06f66-7b35-4c23-b492-3f795e6b6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c01a19e7-3772-4620-bebe-ab019a4c02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8dc56ae3-9c3c-41d4-b173-a3e836c44493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.labels = df.columns #устанавливаем метки столбцов\n",
    "        self.data = df.to_dict(orient='records')\n",
    "        print(self.data[1:3])\n",
    "        self.tokenizer = tokenizer\n",
    "        x = self.average_len(df)\n",
    "        self.max_length = x \n",
    "\n",
    "    def average_len(self,df):\n",
    "        sum_ = 0\n",
    "        for example in df[self.labels[1]]:\n",
    "          sum_ += len(example)\n",
    "        x  = 2\n",
    "        while x < sum_/len(df):\n",
    "          x = x * 2\n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "          x = self.data[idx][self.labels[0]]\n",
    "          y = self.data[idx][self.labels[1]]\n",
    "          z = self.data[idx][self.labels[2]]\n",
    "          # text = f\"{x} | {y}\"\n",
    "          text = f\"{x} | {y} | {z}\"\n",
    "    \n",
    "          tokens = self.tokenizer.encode_plus(text, \n",
    "                                              return_tensors='pt', \n",
    "                                              max_length=self.max_length, \n",
    "                                              padding='max_length', \n",
    "                                              truncation=True) \n",
    "            \n",
    "          return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "125b5d92-2e56-401b-b529-57c932ac35c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Vocal cord polyp', 'Symptoms': 'Hoarseness, Vocal Changes, Vocal Fatigue', 'Treatments': 'Voice Rest, Speech Therapy, Surgical Removal'}, {'Name': 'Turner syndrome', 'Symptoms': 'Short stature, Gonadal dysgenesis, Webbed neck, Lymphedema', 'Treatments': 'Growth hormone therapy, Estrogen replacement therapy, Cardiac and renal evaluations'}]\n"
     ]
    }
   ],
   "source": [
    "data_sample = LanguageDataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ee221475-94c8-4f16-91c2-b12a5a387b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data_sample))\n",
    "valid_size = len(data_sample) - train_size\n",
    "\n",
    "train_data, valid_data = random_split(data_sample, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "531862ae-085e-4d3f-8b73-9a9f16f8429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True) #дополнительно перемешаем данные\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "65f3c5c2-3392-4020-a039-53cf6ffee366",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1d661670-28b1-452c-b0e2-bab4c0f5a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "model_name = 'distilgpt2'\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b037673e-393e-46c8-aae1-8d730edec3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6da009da-9efe-4635-bd56-75759169eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['epoch', \n",
    "                                'transformer', \n",
    "                                'batch_size', \n",
    "                                'gpu',\n",
    "                                'training_loss', \n",
    "                                'validation_loss', \n",
    "                                'epoch_duration_sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d04f2b3f-83f0-4151-96ed-50cbfd78283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ddd96ab0-7d0c-4849-a275-26e75010a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_loader, batch_size, model_name, sheduler, tokenizer):\n",
    "  for epoch in range(num_epochs):\n",
    "      start_time = time.time()  # Start the timer for the epoch\n",
    "      #переводим модель в режим обучения\n",
    "      model.train()\n",
    "      epoch_training_loss = 0\n",
    "\n",
    "      train_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}\")\n",
    "\n",
    "      for batch in train_iterator:\n",
    "          optimizer.zero_grad()\n",
    "          inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "          targets = inputs.clone()\n",
    "\n",
    "          outputs = model(input_ids=inputs, labels=targets)\n",
    "\n",
    "          loss = outputs.loss\n",
    "          \n",
    "          #выполняем обратный переход\n",
    "          loss.backward()\n",
    "          #обновляем веса\n",
    "          optimizer.step()\n",
    "\n",
    "          train_iterator.set_postfix({'Training Loss': loss.item()})\n",
    "          epoch_training_loss += loss.item()\n",
    "\n",
    "      avg_epoch_training_loss = epoch_training_loss / len(train_iterator)\n",
    "\n",
    "      #переводим модель в режим ответов\n",
    "      model.eval()\n",
    "      \n",
    "      epoch_validation_loss = 0\n",
    "      total_loss = 0\n",
    "      valid_iterator = tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
    "      with torch.no_grad():\n",
    "          for batch in valid_iterator:\n",
    "              inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "              targets = inputs.clone()\n",
    "              outputs = model(input_ids=inputs, labels=targets)\n",
    "              loss = outputs.loss\n",
    "              total_loss += loss\n",
    "              valid_iterator.set_postfix({'Validation Loss': loss.item()})\n",
    "              epoch_validation_loss += loss.item()\n",
    "\n",
    "      avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)\n",
    "\n",
    "      end_time = time.time()  # закончилась одна эпоха\n",
    "      epoch_duration_sec = end_time - start_time\n",
    "\n",
    "      new_row = {'transformer': model_name,\n",
    "                'batch_size': batch_size,\n",
    "                'gpu': gpu,\n",
    "                'epoch': epoch+1,\n",
    "                'training_loss': avg_epoch_training_loss,\n",
    "                'validation_loss': avg_epoch_validation_loss,\n",
    "                'epoch_duration_sec': epoch_duration_sec}  \n",
    "\n",
    "      results.loc[len(results)] = new_row\n",
    "      print(f\"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}\")\n",
    "\n",
    "      early_stopping(epoch_validation_loss, model)\n",
    "      if early_stopping.early_stop:\n",
    "          print(\"Early stopping\")\n",
    "          break\n",
    "\n",
    "    # Load the best model\n",
    "      early_stopping.load_best_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "1ee5fa8b-4195-440f-b45a-58801d26999a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10 Batch Size: 8, Transformer: distilgpt2: 100%|████████████████████████████████████| 40/40 [00:02<00:00, 13.65it/s, Training Loss=0.68]\n",
      "Validation Epoch 1/10: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 39.95it/s, Validation Loss=0.207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Loss: 0.2901248037815094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10 Batch Size: 8, Transformer: distilgpt2: 100%|████████████████████████████████████| 40/40 [00:02<00:00, 13.60it/s, Training Loss=0.19]\n",
      "Validation Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.27it/s, Validation Loss=0.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.2988549768924713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10 Batch Size: 8, Transformer: distilgpt2: 100%|███████████████████████████████████| 40/40 [00:02<00:00, 13.68it/s, Training Loss=0.233]\n",
      "Validation Epoch 3/10: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.76it/s, Validation Loss=0.206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation Loss: 0.29911547899246216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10 Batch Size: 8, Transformer: distilgpt2: 100%|███████████████████████████████████| 40/40 [00:03<00:00, 13.28it/s, Training Loss=0.357]\n",
      "Validation Epoch 4/10: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 39.89it/s, Validation Loss=0.217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Loss: 0.30714571475982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10 Batch Size: 8, Transformer: distilgpt2: 100%|███████████████████████████████████| 40/40 [00:02<00:00, 13.42it/s, Training Loss=0.231]\n",
      "Validation Epoch 5/10: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.17it/s, Validation Loss=0.222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation Loss: 0.31564903259277344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10 Batch Size: 8, Transformer: distilgpt2: 100%|████████████████████████████████████| 40/40 [00:03<00:00, 13.17it/s, Training Loss=0.18]\n",
      "Validation Epoch 6/10: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.94it/s, Validation Loss=0.231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation Loss: 0.32396718859672546\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "sheduler  =  ExponentialLR(optimizer, gamma=0.8)\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.01)\n",
    "train_model(model, num_epochs, train_loader, batch_size, model_name, tokenizer, sheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "12098235-1040-4fb0-8a33-ba0f40e5113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panic disorder  | Severe abdominal pain, bloating, nausea, vomiting, fever, rapid heart rate, dizziness or lightheadedness (in severe cases) | Emergency medical attention, medications to manage symptoms, lifestyle modifications (e.g., avoiding alcohol, maintaining a healthy weight), medication (e-cigarettes, diuretics , antihistamines). Anticoagulants\n"
     ]
    }
   ],
   "source": [
    "# input_str = \"Cellulitis\"\n",
    "input_str = \"Panic disorder \"\n",
    "# input_str = \"Eye alignment disorder\"\n",
    "\n",
    "input_ids = tokenizer.encode(input_str, return_tensors='pt').to(device)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100, # максимальная длина выходной последовательности. \n",
    "    # Генерация последовательности будет происходить, пока не будет выбран \n",
    "    # токен остановки или пока не будет достигнута максимальная длина\n",
    "    num_return_sequences=1, # количество возвращаемых ответов\n",
    "    do_sample=True,\n",
    "    top_k=10, # количество токенов с наибольшей вероятностью, среди которых будет происходить выбор следующего токена\n",
    "    top_p=0.8, # вероятность, которую не должна превышать сумма вероятностей наиболее вероятных токенов на каждом шаге.\n",
    "    temperature=0.91, #отвечает за \"креативность\" модели\n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
