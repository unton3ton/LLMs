

# Sources
 
* [Большие языковые модели для бизнеса: как создать умную базу знаний  Источник: https://secrets.tinkoff.ru/blogi-kompanij/sozdanie-umnoj-bazy-znanij/?internal_source=copypaste © Бизнес‑секреты](https://secrets.tinkoff.ru/blogi-kompanij/sozdanie-umnoj-bazy-znanij/)
* [arham-kk / gpt2-finetune ](https://github.com/arham-kk/gpt2-finetune/tree/main)
* [Fine Tuning Large Language Model (LLM)](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)
* [DuckDuckGo AI Chat](https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1)
* [Дообучаем языковую модель GPT2 с помощью Torch](https://habr.com/ru/articles/859250/)
* [distilbert / distilgpt2](https://huggingface.co/distilbert/distilgpt2)
* [QuyenAnhDE / Diseases_Symptoms](https://huggingface.co/datasets/QuyenAnhDE/Diseases_Symptoms?row=12)
* [How to handle overfitting in PyTorch models using Early Stopping](https://www.geeksforgeeks.org/how-to-handle-overfitting-in-pytorch-models-using-early-stopping/)
* [Продвинутые методы улучшения качества LLM-решений: Fine-tuning](https://gopractice.ru/skills/llm-fine-tuning/)
